import{_ as p,a as l,b as r,c,d as u}from"./robustness_test_plot-d3hRRG04.js";import{_ as d,c as m,a as t,b as e,d as n,e as o,w as i,r as h,o as b}from"./app-D_z27tro.js";const v={};function g(k,s){const a=h("RouteLink");return b(),m("div",null,[s[9]||(s[9]=t(`<p>In Tensorboard, we can see many useful metrics that can monitor the training process and the convergence of the model. They all correspond to the information in the dictionary returned by the <code>forward()</code> function of the model in <code>my_model.py</code>.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Build the output dictionary</span></span>
<span class="line">        output_dict <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token string">&quot;backward_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>seg_pred<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;pred_label&quot;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>cls_pred<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_loss&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;total_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;seg_loss&quot;</span><span class="token punctuation">:</span> seg_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;cls_loss&quot;</span><span class="token punctuation">:</span> cls_loss</span>
<span class="line">            <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_image&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> seg_pred<span class="token punctuation">,</span></span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">        <span class="token keyword">return</span> output_dict</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The visualization of the loss function corresponds to the dictionary corresponding to the <code>visual_loss</code> field:</p><p><img src="`+p+'" alt=""></p><p>The calculation of the evaluation metrics comes from the results of <code>pred_mask</code> and <code>pred_label</code> and is obtained by calculating with <code>mask</code>:</p><p><img src="'+l+'" alt="alt text"></p><p>The visualization of the predicted results, obtained from the <code>visual_image</code> field, and the default input images such as <code>image</code>, <code>mask</code> are also automatically visualized and output, which can be used to directly observe where the model&#39;s current predictions are not good, facilitating further model improvement.</p><p><img src="'+r+`" alt=""></p><div class="hint-container note"><p class="hint-container-title">Note</p><p>The tutorial should have image samples here. If you do not see the images, please check your network connection or enable VPN.</p></div><p>All the weights obtained after training (Checkpoint) are saved in the path corresponding to <code>base_dir</code> at the beginning of the training <code>train_mymodel.sh</code> script. The log files of Tensorboard are also saved here for subsequent use and log review.</p><p>In addition to Tensorboard logs, we also provide a plain text log <code>log.txt</code> for archiving, which contains simple content, including all scalar information after each Epoch. An example is as follows:</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">......</span>
<span class="line">{&quot;train_lr&quot;: 5.068414063259753e-05, &quot;train_total_loss&quot;: 0.040027402791482446, &quot;train_seg_loss&quot;: 0.04001608065957309, &quot;train_cls_loss&quot;: 1.1322131909352606e-05, &quot;test_pixel-level F1&quot;: 0.6269838496863315, &quot;epoch&quot;: 100}</span>
<span class="line">{&quot;train_lr&quot;: 4.9894792537480576e-05, &quot;train_total_loss&quot;: 0.03938291078949974, &quot;train_seg_loss&quot;: 0.039372251576574625, &quot;train_cls_loss&quot;: 1.0659212925112626e-05, &quot;epoch&quot;: 101}</span>
<span class="line">{&quot;train_lr&quot;: 4.910553386394297e-05, &quot;train_total_loss&quot;: 0.039195733024078264, &quot;train_seg_loss&quot;: 0.039184275720948555, &quot;train_cls_loss&quot;: 1.1457303129702722e-05, &quot;epoch&quot;: 102}</span>
<span class="line">{&quot;train_lr&quot;: 4.8316563303634596e-05, &quot;train_total_loss&quot;: 0.0385435631179897, &quot;train_seg_loss&quot;: 0.03853294577689024, &quot;train_cls_loss&quot;: 1.061734109946144e-05, &quot;epoch&quot;: 103}</span>
<span class="line">{&quot;train_lr&quot;: 4.752807947567499e-05, &quot;train_total_loss&quot;: 0.035692626619510615, &quot;train_seg_loss&quot;: 0.03568181328162471, &quot;train_cls_loss&quot;: 1.0813337885906548e-05, &quot;test_pixel-level F1&quot;: 0.6672104743469334, &quot;epoch&quot;: 104}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The model is tested every 4 Epochs, so only the corresponding epoch will save <code>test_pixel-level F1</code>.</p><p>Thus, we have explained all the output content during the training process.</p><h3 id="conducting-tests" tabindex="-1"><a class="header-anchor" href="#conducting-tests"><span>Conducting Tests</span></a></h3><p>We saw in the previous metric tests that the model still had an upward trend at the 104th Epoch, but to save time, we stopped training here and proceeded to subsequent tests.</p><p>The gap between tamper detection datasets is quite large, and generalization performance is the most important indicator to measure model performance, so we hope to measure all indicators at once. Unlike previous tutorials, we need to use the <code>test_datasets.json</code> file that can cover multiple test datasets at once to assist in testing. The format is as follows, and we also provide a sample of this file in the files after <code>benco init</code>.</p><div class="language-JSON line-numbers-mode" data-highlighter="prismjs" data-ext="JSON"><pre><code><span class="line">{</span>
<span class="line">    &quot;Columbia&quot;: &quot;/mnt/data0/public_datasets/IML/Columbia.json&quot;,</span>
<span class="line">    &quot;NIST16_1024&quot;: &quot;/mnt/data0/public_datasets/IML/NIST16_1024&quot;,</span>
<span class="line">    &quot;NIST16_cleaned&quot;: &quot;/mnt/data0/public_datasets/IML/NIST16_1024_cleaning&quot;,</span>
<span class="line">    &quot;coverage&quot;: &quot;/mnt/data0/public_datasets/IML/coverage.json&quot;,</span>
<span class="line">    &quot;CASIAv1&quot;: &quot;/mnt/data0/public_datasets/IML/CASIA1.0&quot;,</span>
<span class="line">    &quot;IMD20_1024&quot;: &quot;/mnt/data0/public_datasets/IML/IMD_20_1024&quot;</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,18)),e("p",null,[s[2]||(s[2]=n("You need to preprocess each dataset in advance, and the dataset index is in the ")),o(a,{to:"/imdl_data_model_hub/data/IMDLdatasets.html"},{default:i(()=>s[0]||(s[0]=[n("Tamper Detection Dataset Index")])),_:1}),s[3]||(s[3]=n(" section, and the format requirements are in the ")),o(a,{to:"/guide/quickstart/0_dataprepare.html"},{default:i(()=>s[1]||(s[1]=[n("Dataset Preparation Section")])),_:1}),s[4]||(s[4]=n(". The above paths must be organized in the format of ")),s[5]||(s[5]=e("code",null,"ManiDataset",-1)),s[6]||(s[6]=n(" or ")),s[7]||(s[7]=e("code",null,"JsonDataset",-1)),s[8]||(s[8]=n("."))]),s[10]||(s[10]=t(`<p>Then we modify the <code>test_mymodel.sh</code> file to pass in the correct parameters, mainly including the following fields:</p><ul><li>Change <code>--mymodel</code> to <code>MyConvNeXt</code></li><li>Remove unnecessary <code>--MyModel_Customized_param</code> and <code>--pre_trained_weights</code> especially <code>pretrained_path</code> is usually initialized before model training. It is irrelevant during the testing phase.</li><li>Set <code>--checkpoint_path</code> to the folder where all <code>checkpoint-xx.pth</code> are output during training. It will automatically read all files ending with <code>.pth</code> under this folder and determine which epoch the checkpoint comes from based on the number in the filename to correctly plot the test metrics line chart.</li><li>Set <code>--test_data_json</code> to the path of the JSON containing multiple test set information mentioned earlier.</li><li>Other parameters can be set according to the memory and other conditions as appropriate,</li></ul><div class="hint-container important"><p class="hint-container-title">Note</p><p>If you chose <code>--if_padding</code> during training, this means that the dataloader will organize all images in the 0-padding manner of <a href="https://github.com/SunnyHaze/IML-ViT" target="_blank" rel="noopener noreferrer">IML-ViT</a>, not the <code>--if_resizing</code> of most models. Then make sure that this parameter is consistent between training and testing, otherwise, there will definitely be performance loss due to the inconsistency between the training set and the test set.</p><p>You can double-check whether padding or resizing is correctly selected through the pictures visualized by Tensorboard!</p></div><p>A modified <code>test_mymodel.sh</code> is as follows:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token assign-left variable">base_dir</span><span class="token operator">=</span><span class="token string">&quot;./eval_dir&quot;</span></span>
<span class="line"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> <span class="token variable">\${base_dir}</span></span>
<span class="line"></span>
<span class="line"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\\</span></span>
<span class="line">torchrun  <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--standalone</span>    <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nnodes</span><span class="token operator">=</span><span class="token number">1</span>     <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">./test.py <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--model</span> MyConvNeXt <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--world_size</span> <span class="token number">1</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_data_json</span> <span class="token string">&quot;./test_datasets.json&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--checkpoint_path</span> <span class="token string">&quot;./output_dir/&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_batch_size</span> <span class="token number">32</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--image_size</span> <span class="token number">512</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--if_resizing</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--output_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--log_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line"><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span> <span class="token variable">\${base_dir}</span>/error.log <span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span><span class="token variable">\${base_dir}</span>/logs.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then, remember to change <code>from mymodel import MyModel</code> at the beginning of <code>test.py</code> to <code>from mymodel import MyConvNeXt</code>.</p><p>At this point, running the following command can start batch testing metrics on various test sets:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token function">sh</span> test_mymodel.sh</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>At this time, you can also view the test progress and results through Tensorboard. You can filter <code>eval_dir</code> in the <code>filter</code> box on the left to only view the output results of this test.</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">tensorboard <span class="token parameter variable">--logdir</span> ./</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>The line charts of metrics obtained from multiple datasets after testing are as follows. Choose the Checkpoint with the best comprehensive performance and record the corresponding data in the paper.</p><p><img src="`+c+`" alt=""></p><h3 id="robustness-testing" tabindex="-1"><a class="header-anchor" href="#robustness-testing"><span>Robustness Testing</span></a></h3><p>Robustness testing introduces two dimensions of &quot;attack type&quot; and &quot;attack strength&quot; for grid search (<code>gird search</code>), so it is generally only the best-performing checkpoint during the test phase that undergoes robustness testing.</p><p>Accordingly, in the <code>test_robust_mymodel.sh</code> file, unlike <code>test_mymodel.sh</code>, the <code>--checkpoint_path</code> field here points to a specific checkpoint, not a folder.</p><p>The other fields are the same, remove unnecessary parameters, fill in the required parameters, and remember to change <code>from mymodel import MyModel</code> at the beginning of <code>test_robust.py</code> to <code>from mymodel import MyConvNeXt</code>.</p><p>The <code>test_robust_mymodel.sh</code> I finally used is as follows:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token assign-left variable">base_dir</span><span class="token operator">=</span><span class="token string">&quot;./eval_robust_dir&quot;</span></span>
<span class="line"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> <span class="token variable">\${base_dir}</span></span>
<span class="line"></span>
<span class="line"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\\</span></span>
<span class="line">torchrun  <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--standalone</span>    <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nnodes</span><span class="token operator">=</span><span class="token number">1</span>     <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">./test_robust.py <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--model</span> MyConvNeXt <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--world_size</span> <span class="token number">1</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_data_path</span> <span class="token string">&quot;/mnt/data0/public_datasets/IML/CASIA1.0&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--checkpoint_path</span> <span class="token string">&quot;/mnt/data0/xiaochen/workspace/ForensicHub_pure/guide/benco/output_dir/checkpoint-92.pth&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_batch_size</span> <span class="token number">32</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--image_size</span> <span class="token number">512</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--if_resizing</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--output_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--log_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line"><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span> <span class="token variable">\${base_dir}</span>/error.log <span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span><span class="token variable">\${base_dir}</span>/logs.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The specific adjustment of attack strategies and intensities in robustness testing requires modification of <code>test_robust.py</code>. Please locate this modifiable code by searching for <code>TODO</code>:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;=================================================</span>
<span class="line">    Modify here to Set the robustness test parameters TODO</span>
<span class="line">    ===================================================&quot;&quot;&quot;</span></span>
<span class="line">    robustness_list <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">            GaussianBlurWrapper<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            GaussianNoiseWrapper<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> </span>
<span class="line">            JpegCompressionWrapper<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The lists behind these <code>wrapper</code> represent the specific strengths of the attacks, and they internally encapsulate the Transform provided by <a href="https://github.com/albumentations-team/albumentations" target="_blank" rel="noopener noreferrer">Albumentation</a> to implement the attack. The implementation of the <code>wrapper</code> itself, please refer to this <a href="https://github.com/scu-zjz/ForensicHub/blob/main/ForensicHub/transforms/robustness_wrapper.py" target="_blank" rel="noopener noreferrer">link</a>.</p><p>In particular, you can refer to the implementation of the <code>wrapper</code> in the current path to encapsulate a new custom <code>wrapper</code>, and then import your own wrapper here like <code>from mymodel import MyConvNeXt</code>. This way, you can achieve a custom flexible robustness test without modifying the source code.</p><hr><p>For test results, similarly, you can view them through Tensorboard:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">tensorboard <span class="token parameter variable">--logdir</span> ./</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>At this time, there may be many different records. Please make good use of the filter function in the upper left corner of Tensorboard to filter the attack types and corresponding results you need to record.</p><p><img src="`+u+'" alt=""></p><hr><h3 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h3><p>In this way, we have completed the process of designing a model from scratch, training the model, completing testing and robustness testing. If you have any questions or incomplete places, please feel free to raise issues in our repository or contact the author team by email. The suggestions from the first-hand users will be of great help to us and to future scholars!</p>',30))])}const q=d(v,[["render",g]]),y=JSON.parse('{"path":"/guide/quickstart/4_whole_pipeline.html","title":"","lang":"en-US","frontmatter":{"description":"In Tensorboard, we can see many useful metrics that can monitor the training process and the convergence of the model. They all correspond to the information in the dictionary r...","head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/zh/guide/quickstart/4_whole_pipeline.html"}],["meta",{"property":"og:url","content":"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/guide/quickstart/4_whole_pipeline.html"}],["meta",{"property":"og:site_name","content":"ForensicHub Documentation"}],["meta",{"property":"og:description","content":"In Tensorboard, we can see many useful metrics that can monitor the training process and the convergence of the model. They all correspond to the information in the dictionary r..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/images/training/training_loss.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-04-16T09:03:03.000Z"}],["meta",{"property":"article:modified_time","content":"2025-04-16T09:03:03.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/images/training/training_loss.png\\",\\"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/images/training/pixelF1.png\\",\\"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/images/training/train_test_samples.png\\",\\"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/images/training/testing_results.png\\",\\"https://scu-zjz.github.io/ForensicHub-doc/ForensicHub-doc/images/training/robustness_test_plot.png\\"],\\"dateModified\\":\\"2025-04-16T09:03:03.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":3,"title":"Conducting Tests","slug":"conducting-tests","link":"#conducting-tests","children":[]},{"level":3,"title":"Robustness Testing","slug":"robustness-testing","link":"#robustness-testing","children":[]},{"level":3,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]}],"git":{"updatedTime":1744794183000,"contributors":[{"name":"Ma Xiaochen (马晓晨)","username":"","email":"mxch1122@126.com","commits":2}],"changelog":[{"hash":"0e74f1d2aa8755e9efae0840d449e9f06e10925a","time":1744794183000,"email":"mxch1122@126.com","author":"Ma Xiaochen (马晓晨)","message":"[rename] rename all IMDLbenco to ForensicHub"},{"hash":"c131b603f94f974b69bdb6ca4dfc284ba7e4c78f","time":1743461235000,"email":"mxch1122@126.com","author":"Ma Xiaochen (马晓晨)","message":"[update] finish case3 in tutorial"}]},"filePathRelative":"guide/quickstart/4_whole_pipeline.md","autoDesc":true}');export{q as comp,y as data};
