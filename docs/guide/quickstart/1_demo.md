# Hands-on Examples
We believe the fastest way to learn is through "Learn by Doing," so we provide several examples to help users get started quickly.

Overall, IMDL-BenCo helps you quickly develop image tampering detection research projects through command-line calls similar to `git` and `conda`. If you have experience with front-end technologies like Vue, understanding the design paradigm of IMDLBenCo will be very easy, as it is similar to the concept of Vue-cli.

In any case, please first refer to the [Installation](./install.md) to complete the installation of IMDL-BenCo.

## Example Zero: Quick Understanding of the Design Paradigm

### Generating Default Scripts

In a clean working directory, simply run the following command-line instruction to generate all the necessary scripts for the most basic operation. As a default command, omitting `base` will execute the same command.

::: tabs
@tab Full Command
```shell
benco init base
```
@tab Abbreviated Command
```shell
benco init
```
:::

After successful execution, you will see the following files generated in the current directory, with their purposes indicated in the comments:
```bash
.
├── balanced_dataset.json       # Stores dataset paths organized by Protocol-CAT
├── mymodel.py                  # Core model implementation
├── README-IMDLBenCo.md         # A simple readme
├── test_datasets.json          # Stores dataset paths for testing
├── test_mymodel.sh             # Shell script for running tests with parameters
├── test.py                     # Actual Python code for the test script
├── test_robust_mymodel.sh      # Shell script for running robustness tests with parameters
├── test_robust.py              # Actual Python code for robustness testing
├── train_mymodel.sh            # Shell script for training with parameters
└── train.py                    # Actual Python code for the training script
```

::: warning Special Note
If you have already generated the scripts and made modifications, be **very cautious** when calling `benco init` again. IMDLBenCo will overwrite the files one by one after asking for confirmation. If you accidentally proceed, you may lose your modifications. It is highly recommended to use version control with Git to avoid losing your code due to such operations.
:::

### Model File Design Paradigm
IMDLBenCo requires model files to be organized in a specific format to ensure that the input can align with the `DataLoader` and the output can align with the subsequent `Evaluator` and `Visualization tools`.

After executing `benco init`, a simple **single-layer convolution** model is generated by default in `mymodel.py`. You can quickly check its content through the [Github link to mymodel.py](https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/statics/base/mymodel.py).

```python
from IMDLBenCo.registry import MODELS
import torch.nn as nn
import torch

@MODELS.register_module()
class MyModel(nn.Module):
    def __init__(self, MyModel_Customized_param:int, pre_trained_weights:str) -> None:
        """
        The parameters of the `__init__` function will be automatically converted into the parameters expected by the argparser in the training and testing scripts by the framework according to their annotated types and variable names.
        
        In other words, you can directly pass in parameters with the same names and types from the `run.sh` script to initialize the model.
        """
        super().__init__()
        
        # Useless, just an example
        self.MyModel_Customized_param = MyModel_Customized_param
        self.pre_trained_weights = pre_trained_weights

        # A single layer conv2d 
        self.demo_layer = nn.Conv2d(
            in_channels=3,
            out_channels=1,
            kernel_size=3,
            stride=1,
            padding=1,
        )

        # A simple loss
        self.loss_func_a = nn.BCEWithLogitsLoss()
        
    def forward(self, image, mask, label, *args, **kwargs):
        # simple forwarding
        pred_mask = self.demo_layer(image)
        
        # simple loss
        loss_a = self.loss_func_a(pred_mask, mask)
        loss_b = torch.abs(torch.mean(pred_mask - mask))
        combined_loss = loss_a + loss_b
        
        pred_label = torch.mean(pred_mask)
        
        inverse_mask = 1 - mask
        
        # ----------Output interface--------------------------------------
        output_dict = {
            # loss for backward
            "backward_loss": combined_loss,
            # predicted mask, will calculate for metrics automatically
            "pred_mask": pred_mask,
            # predicted binary label, will calculate for metrics automatically
            "pred_label": pred_label,

            # ----values below is for visualization----
            # automatically visualize with the key-value pairs
            "visual_loss": {
                # keys here can be customized by yourself.
                "predict_loss": combined_loss,
                'loss_a' : loss_a,
                "I am loss_b :)": loss_b, 
            },

            "visual_image": {
                # keys here can be customized by yourself.
                # Various intermediate masks, heatmaps, and feature maps can be appropriately converted into RGB or single-channel images for visualization here.
                "pred_mask": pred_mask,
                "reverse_mask" : inverse_mask, 
            }
            # -------------------------------------------------------------
        }
        
        return output_dict
    
if __name__ == "__main__":
    print(MODELS)
```

**Introducing the model file design requirements for IMDLBenCo in the order of the code:**
- Line 5: `@MODELS.register_module()`
  - Registers the model to the global registry of IMDLBenCo using a registration mechanism, allowing other scripts to quickly call this class via a string.
  - If you are unfamiliar with the registration mechanism, in short: it **automatically maintains a dictionary mapping from strings to corresponding classes**, facilitating the "free" passing of parameters.
  - In practice, you can load a custom or pre-existing model by passing the registered "class name string" to the `--model` function in the shell script for training. For more details, please refer to [this link](https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/statics/model_zoo/runs/demo_train_mvss.sh#L10).
- Lines 29 and 37: **Loss functions must be defined in the `__init__()` or `forward()` function**
- Line 31: When defining the `forward` function, use `def forward(self, image, mask, label, *args, **kwargs):`
  - It is necessary to include `*args, **kwargs` to receive unused parameters.
    - If you are not familiar with this, please refer to the [Python Official Documentation - 4.8.2. Keyword Arguments](https://docs.python.org/3/tutorial/controlflow.html#keyword-arguments) and the [Chinese version of the Python Official Documentation - 4.8.2 Keyword Arguments](https://docs.python.org/zh-cn/3/tutorial/controlflow.html#keyword-arguments).
  - The parameter names must exactly match the field names in the dictionary `data_dict` returned by [`abstract_dataset.py`](https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/datasets/abstract_dataset.py). The default fields are shown in the table below:
    - |Key Name|Meaning|Type|
      |:-:|:-:|:-:|
      |image|Input original image|Tensor(B,3,H,W)|
      |mask|Prediction target mask|Tensor(B,1,H,W)|
      |edge_mask|The mask with only the boundary in white obtained by [erosion and dilation](https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html) based on the mask, for models that need boundary loss functions. To reduce computational overhead, the corresponding dataloader will return this key-value pair for the model's `forward()` function only if the training `shell` is passed a parameter like `--edge_mask_width 7`. For example, refer to the [shell](https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/statics/model_zoo/runs/demo_train_iml_vit.sh#L22) and [model forward function](https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/model_zoo/iml_vit/iml_vit.py#L125) of `IML-ViT`.<br>If the edge mask is not needed for subsequent loss calculations, neither the shell needs to pass it, nor does the model's `forward()` function need to prepare a parameter named `edge_mask`, as seen in the [shell](https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/statics/model_zoo/runs/demo_train_object_former.sh) and [model forward function](https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/model_zoo/object_former/object_former.py#L285) of `ObjectFormer`.|Tensor(B,1,H,W)|
      |label|Zero-one label for image-level prediction|Tensor(B,1)|
      |shape|The shape of the image passed into the model for training after padding or resizing|Tensor(B,2), one value for each dimension representing H and W|
      |original_shape|The shape of the original input image|Tensor(B,2), one value for each dimension representing H and W|
      |name|Path and file name of the image|str|
      |shape_mask|In case of padding, only the pixels within this mask that are 1 are calculated as the final metric, with 1 defaulting to a square area as large as the original image|Tensor(B,1,H,W)|
    - For different tasks, you can selectively use these fields as inputs to the model.
    - Additionally, for models like CAT-Net that require JPEG-related image materials, we have designed a post-processing function `post_func` to generate more content based on the existing fields, ensuring that the corresponding fields in the `forward` function are aligned. **Custom models with similar needs can also use this paradigm to introduce other modalities of information in the dataloader.** Here is the example of CAT-Net:
      - [Github link to `cat_net_post_function`](https://github.com/scu-zjz/IMDLBenCo/blob/c2d6dc03eab3f33461690d5026b43afdac22f70c/IMDLBenCo/model_zoo/cat_net/cat_net_post_function.py#L7-L10), which includes additional fields `DCT_coef` and `q_tables` to provide extra modalities as model inputs.
      - [Github link to `cat_net_model`](https://github.com/scu-zjz/IMDLBenCo/blob/c2d6dc03eab3f33461690d5026b43afdac22f70c/IMDLBenCo/model_zoo/cat_net/cat_net.py#L30), where the parameter list of the `forward` function needs to have corresponding fields to receive the extra input information.
- Lines 36 to 38: All loss functions must be calculated within the `forward` function.
- Lines 45 to 70: The output dictionary. <span style="color: red;font-weight: bold;">Very Important!</span> The functions of each field in the dictionary are as follows:
  - |Key|Meaning|Type|
    |:-:|:-:|:-:|
    |backward_loss|Loss function directly used for backpropagation|Tensor(1)|
    |pred_mask|Predicted mask, directly used for subsequent metric calculations|Tensor(B,1,H,W)|
    |pred_label|Predicted zero-one label, directly used for subsequent metric calculations|Tensor(B,1)|
    |visual_loss|Scalars to be visualized. You can name any number of keys with arbitrary names and pass in the corresponding scalars, which will be automatically visualized based on the key names|Dict()|
    |visual_image|Images, feature maps, and various masks to be visualized. You can name any number of keys with arbitrary names and pass in the corresponding Tensors, which will be automatically visualized based on the key names|Dict()|
  - Be sure to organize in this format to properly integrate into subsequent metric calculations, visualization, and other processes.

This concludes the introduction to the characteristics and considerations of model code implementation in IMDLBenCo.
